{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "320c488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import dlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0faceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerificationSystem:\n",
    "    def __init__(self,\n",
    "                 reference_image_url,\n",
    "                 shape_predictor_path='shape_predictor_68_face_landmarks.dat',\n",
    "                 face_match_threshold=0.6, #lower means stricter\n",
    "                 eye_ar_threshold=0.25, #lower means eyes are closed\n",
    "                 eye_ar_consec_frames=3, #no of consecutive frame below the threshold to count as a blink\n",
    "                 required_blinks=1):\n",
    "\n",
    "        self.reference_image_url = reference_image_url\n",
    "        self.face_match_threshold = face_match_threshold\n",
    "        self.shape_predictor_path = shape_predictor_path\n",
    "        self.eye_ar_threshold = eye_ar_threshold\n",
    "        self.eye_ar_consec_frames = eye_ar_consec_frames\n",
    "        self.required_blinks = required_blinks\n",
    "\n",
    "        self.counter = 0\n",
    "        self.total_blinks = 0\n",
    "        self.liveness_passed = False\n",
    "        self.verification_passed = False\n",
    "\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "\n",
    "        self.predictor = dlib.shape_predictor(self.shape_predictor_path)\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    def eye_aspect_ratio(self, eye):\n",
    "        A = np.linalg.norm(eye[1] - eye[5])\n",
    "        B = np.linalg.norm(eye[2] - eye[4])\n",
    "        C = np.linalg.norm(eye[0] - eye[3])\n",
    "        return (A + B) / (2.0 * C)\n",
    "\n",
    "    def fetch_reference_image(self):\n",
    "        try:\n",
    "            print(f\"Fetching reference image from: {self.reference_image_url}\")\n",
    "            headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "            response = requests.get(self.reference_image_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            return cv.cvtColor(np.array(img), cv.COLOR_RGB2BGR)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching reference image: {e}\")\n",
    "            return None\n",
    "\n",
    "    def initialize_reference_encoding(self):\n",
    "        reference_image_np = self.fetch_reference_image()\n",
    "        if reference_image_np is None:\n",
    "            raise ValueError(\"Reference image could not be loaded.\")\n",
    "\n",
    "        reference_image_rgb = cv.cvtColor(reference_image_np, cv.COLOR_BGR2RGB)\n",
    "        ref_face_locations = face_recognition.face_locations(reference_image_rgb)\n",
    "        if not ref_face_locations:\n",
    "            raise ValueError(\"No face found in the reference image.\")\n",
    "\n",
    "        ref_face_encoding = face_recognition.face_encodings(reference_image_rgb, ref_face_locations)[0]\n",
    "        self.known_face_encodings = [ref_face_encoding]\n",
    "        self.known_face_names = [\"Registered User\"]\n",
    "\n",
    "    def run_verification(self):\n",
    "        self.initialize_reference_encoding()\n",
    "\n",
    "        video_capture = cv.VideoCapture(0)\n",
    "        if not video_capture.isOpened():\n",
    "            raise RuntimeError(\"Error: Could not open webcam.\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame.\")\n",
    "                break\n",
    "\n",
    "            gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "            faces = self.detector(gray)\n",
    "\n",
    "            display_text = \"Status: Initializing...\"\n",
    "            text_color = (0, 255, 255)\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                display_text = \"Status: No face detected.\"\n",
    "                text_color = (0, 0, 255)\n",
    "                self.verification_passed = False\n",
    "                self.liveness_passed = False\n",
    "                self.total_blinks = 0\n",
    "                self.counter = 0\n",
    "\n",
    "            elif len(faces) > 1:\n",
    "                display_text = \"Status: Multiple persons detected!!\"\n",
    "                text_color = (0, 0, 255)\n",
    "                self.verification_passed = False\n",
    "                self.liveness_passed = False\n",
    "                self.total_blinks = 0\n",
    "                self.counter = 0\n",
    "\n",
    "            else:\n",
    "                shape = self.predictor(gray, faces[0])\n",
    "                landmarks = np.array([(p.x, p.y) for p in shape.parts()])\n",
    "\n",
    "                face_locations = face_recognition.face_locations(rgb)\n",
    "                face_encodings = face_recognition.face_encodings(rgb, face_locations)\n",
    "\n",
    "                if face_encodings:\n",
    "                    face_encoding = face_encodings[0]\n",
    "                    face_location = face_locations[0]\n",
    "\n",
    "                    matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding, tolerance=self.face_match_threshold)\n",
    "                    name = \"Unknown User\"\n",
    "\n",
    "                    if True in matches:\n",
    "                        name = self.known_face_names[matches.index(True)]\n",
    "                        self.verification_passed = True\n",
    "                        display_text = f\"Verification: {name} (Match)\"\n",
    "                        text_color = (0, 255, 0)\n",
    "                    else:\n",
    "                        self.verification_passed = False\n",
    "                        display_text = \"User not Verified.\"\n",
    "                        text_color = (0, 0, 255)\n",
    "                        self.liveness_passed = False\n",
    "                        self.total_blinks = 0\n",
    "                        self.counter = 0\n",
    "\n",
    "                    if self.verification_passed and not self.liveness_passed:\n",
    "                        left_eye = landmarks[36:42]\n",
    "                        right_eye = landmarks[42:48]\n",
    "                        ear = (self.eye_aspect_ratio(left_eye) + self.eye_aspect_ratio(right_eye)) / 2.0\n",
    "\n",
    "                        if ear < self.eye_ar_threshold:\n",
    "                            self.counter += 1\n",
    "                        else:\n",
    "                            if self.counter >= self.eye_ar_consec_frames:\n",
    "                                self.total_blinks += 1\n",
    "                            self.counter = 0\n",
    "\n",
    "                        if self.total_blinks >= self.required_blinks:\n",
    "                            self.liveness_passed = True\n",
    "                            text_color = (0, 255, 0)\n",
    "\n",
    "                        cv.putText(frame, f\"Liveness: Blinks {self.total_blinks}/{self.required_blinks}\", (10, 80),\n",
    "                                   cv.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)\n",
    "\n",
    "                    elif self.liveness_passed:\n",
    "                        cv.putText(frame, \"LIVENESS CHECK: PASSED!!\", (10, 80),\n",
    "                                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                    # Draw bounding box\n",
    "                    top, right, bottom, left = face_location\n",
    "                    cv.rectangle(frame, (left, top), (right, bottom), text_color, 2)\n",
    "                    cv.putText(frame, name, (left + 6, bottom - 6),\n",
    "                               cv.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "                    if self.verification_passed and self.liveness_passed:\n",
    "                        display_text = \"Verification and Liveness: PASSED!\"\n",
    "                        text_color = (0, 255, 0)\n",
    "                    elif self.verification_passed:\n",
    "                        display_text = \"Liveness Status: Not Passed!\"\n",
    "                        text_color = (0, 255, 255)\n",
    "\n",
    "            cv.putText(frame, display_text, (10, 30), cv.FONT_HERSHEY_SIMPLEX, 0.8, text_color, 2)\n",
    "            cv.imshow(\"AI Verification System\", frame)\n",
    "\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        video_capture.release()\n",
    "        cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7c7cdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching reference image from: https://i.postimg.cc/Gt1F6PLH/my-pic.jpg\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    system = FaceVerificationSystem(\n",
    "        reference_image_url=\"https://i.postimg.cc/Gt1F6PLH/my-pic.jpg\"\n",
    "    )\n",
    "    system.run_verification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
